confusionMatrix(a,b)
b
a
set.seed(22-10-2017)
amostra=sample(1:2, 2997, replace=T, prob=c(0.632,1-0.632))
basefator=na.omit(basefator)
train=basefator[amostra==1,]
test=basefator[amostra==2,]
#k - fold cress validation
trainControl = trainControl(method="cv", number=10, classProbs = T)
#Treina uma arvore de decisao
tree = train(condenado ~. , data = na.omit(train), method="rpart", trControl=trainControl)
#Verifica o resultado da validacao cruzada
print(tree)
plot(tree)
predictions = predict(tree, newdata = test[,-19])
a=ifelse(test%>%dplyr::select(condenado)=="Sim",1,0)
b=ifelse(predictions=="Sim",1,0)
confusionMatrix(a,b)
plot(tree$finalModel)
text(tree$finalModel)
plot(tree$finalModel)
text(tree$finalModel)
?train
print(tree)
plot(tree$finalModel)
text(tree$finalModel)
library(rattle)
install.packages(rattle)
install.packages("rattle")
fancyRpartPlot(tree$finalModel)
library(rattle)
library(rattle)
fancyRpartPlot(tree$finalModel)
```
varmodelo%>%
dplyr::select(condenado, everything())%>%
ggpairs( lower = list(continuous = my_fn))
my_fn <- function(data, mapping, method="glm", ...){
p <- ggplot(data = data, mapping = mapping) +
geom_point() +
geom_smooth(method=method, ...)
p
}
varmodelo%>%
dplyr::select(condenado, everything())%>%
ggpairs( lower = list(continuous = my_fn))
na.omit(varmodelo)%>%
dplyr::select(condenado, everything())%>%
ggpairs( lower = list(continuous = my_fn))
base=na.omit(base)
base=as.matrix(base)
base[,-19]
Y=decodeClassLabels(base[,19])
Y
#Plotagem para curva de aprendizado:
plot(modelo_mlp$IterativeFitError, type="n", main="Curva de Aprendizagem", xlab="Iteração", ylab="Erro médio quadrado", cex.lab=1.5)
#Começando a organizar os dados:
base=na.omit(base)
base=as.matrix(base)
X= base[,-19]
Y=decodeClassLabels(base[,19])
#Conjuntos de treinamentos devem ser criados:
d_separado=splitForTrainingAndTest(X,Y,ratio=0.1)
#Comando para normalizar os dados:
d_normalizado=normTrainingAndTestSet(d_separado, dontNormTargets = TRUE, type="0_1")
#Funcao de Treinamento;
#Obs.: quantidade de camadas escondidas e o numero de neuronios foram escolhas arbitrarias
modelo_mlp= mlp(d_separado$inputsTrain,
d_separado$targetsTrain,
size=c(5),
maxit=5000,
initFunc = "Randomize_Weights",
learnFunc = "Std_Backpropagation",
learnFuncParams = c(0.5),
hiddenActFunc = "Act_Logistic",
shufflePatterns = T,
linOut = F,
inputsTest = d_separado$inputsTest,
targetsTest = d_separado$targetsTest);modelo_mlp
#Plotagem para curva de aprendizado:
plot(modelo_mlp$IterativeFitError, type="n", main="Curva de Aprendizagem", xlab="Iteração", ylab="Erro médio quadrado", cex.lab=1.5)
lines(modelo_mlp$IterativeFitError,col="1", lwd=3, cex=2) #Erro quadrado medio a cada iteração para o conjunto de treinamento
lines(modelo_mlp$IterativeTestError, col="2", lwd=3, cex=2) ##Erro quadrado medio a cada iteração para o conjunto de teste
legend("top", c("Treinamento", "Teste"), lty=c(1,1), col=c(1,2)) #Clicar para legenda aparecer
library(devtools)
source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')
plot.nnet(modelo_mlp)
predictions = predict(modelo_mlp,d_separado$inputsTest)[,1]
a=d_separado$targetsTest[,1]
b=ifelse(predictions>0.45,0,1);length(b)
confusionMatrix(a,b)
a=d_separado$targetsTest[,2]
b=ifelse(predictions>0.45,0,1);length(b)
confusionMatrix(a,b)
predictions = predict(modelo_mlp,d_separado$inputsTest)[,1]
a=d_separado$targetsTest[,1]
b=ifelse(predictions>0.5,0,1);length(b)
confusionMatrix(a,b)
predict(modelo_mlp,d_separado$inputsTest)[,1]
predict(modelo_mlp,d_separado$inputsTest)
d_separado$inputsTest
modelo_mlp= mlp(d_separado$inputsTrain,
d_separado$targetsTrain,
size=c(5),
maxit=5000,
initFunc = "Randomize_Weights",
learnFunc = "Std_Backpropagation",
learnFuncParams = c(0.2),
hiddenActFunc = "Act_Logistic",
shufflePatterns = T,
linOut = T,
inputsTest = d_separado$inputsTest,
targetsTest = d_separado$targetsTest);modelo_mlp
plot(modelo_mlp$IterativeFitError, type="n", main="Curva de Aprendizagem", xlab="Iteração", ylab="Erro médio quadrado", cex.lab=1.5)
lines(modelo_mlp$IterativeFitError,col="1", lwd=3, cex=2) #Erro quadrado medio a cada iteração para o conjunto de treinamento
lines(modelo_mlp$IterativeTestError, col="2", lwd=3, cex=2) ##Erro quadrado medio a cada iteração para o conjunto de teste
library(devtools)
source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')
source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')
plot.nnet(modelo_mlp)
predictions = predict(modelo_mlp,d_separado$inputsTest)[,1]
a=d_separado$targetsTest[,1]
b=ifelse(predictions>0.5,0,1);length(b)
confusionMatrix(a,b)
modelo_mlp= mlp(d_separado$inputsTrain,
d_separado$targetsTrain,
size=c(3),
maxit=100000,
initFunc = "Randomize_Weights",
#learnFunc = "Std_Backpropagation",
learnFuncParams = c(0.2),
hiddenActFunc = "Act_Logistic",
shufflePatterns = T,
linOut = T,
inputsTest = d_separado$inputsTest,
targetsTest = d_separado$targetsTest);modelo_mlp
plot(modelo_mlp$IterativeFitError, type="n", main="Curva de Aprendizagem", xlab="Iteração", ylab="Erro médio quadrado", cex.lab=1.5)
plot(modelo_mlp$IterativeFitError, type="n", main="Curva de Aprendizagem", xlab="Iteração", ylab="Erro médio quadrado", cex.lab=1.5)
lines(modelo_mlp$IterativeFitError,col="1", lwd=3, cex=2) #Erro quadrado medio a cada iteração para o conjunto de treinamento
lines(modelo_mlp$IterativeTestError, col="2", lwd=3, cex=2) ##Erro quadrado medio a cada iteração para o conjunto de teste
legend("top", c("Treinamento", "Teste"), lty=c(1,1), col=c(1,2)) #Clicar para legenda aparecer
predictions = predict(modelo_mlp,d_separado$inputsTest)[,1]
a=d_separado$targetsTest[,1]
b=ifelse(predictions>0.5,0,1);length(b)
confusionMatrix(a,b)
set.seed(25-10-2017)
#TEste
modelobay=basefator%>%
dplyr::select(-c(maconha, investigacao, quantidade_de_reus))
modelobay$condenado=relevel(modelobay$condenado, "Sim")
#Criando indices para treino e teste
amostra=sample(1:2, 2997, replace=T, prob=c(0.9,1-0.9))
train=modelobay[amostra==1,]
test=modelobay[amostra==2,]
modelo = glm(data=na.omit(train), formula = condenado ~ . , family = binomial("logit"))
library(MASS)
step = stepAIC(modelo, direction = "top")
library(MASS)
step = stepAIC(modelo, direction = "backward")
#Modelo selecionado:
summary(step)
predRL = predict(step, newdata = na.omit(test)%>%dplyr::select(c("sexo", "cocaina","crack", "favela","testemunha_acus","denuncia", "muita_quantidade","confissao")), type = "response")
a=ifelse(na.omit(test)%>%dplyr::select(condenado)=="Sim",1,0)
b=ifelse(predRL>0.5,1,0)
confusionMatrix(a,b)
predRL
summary(predRL)
boxplot(predRL)
b=ifelse(predRL>0.2,1,0)
b=ifelse(predRL>0.2,1,0)
confusionMatrix(a,b)
b=ifelse(predRL>0.15,1,0)
confusionMatrix(a,b)
b=ifelse(predRL>0.1,1,0)
predRL = predict(step, newdata = na.omit(test)%>%dplyr::select(c("sexo", "cocaina","crack", "favela","testemunha_acus","denuncia", "muita_quantidade","confissao")), type = "response")
a=ifelse(na.omit(test)%>%dplyr::select(condenado)=="Sim",1,0)
b=ifelse(predRL>0.1,1,0)
confusionMatrix(a,b)
predRL = predict(step, newdata = na.omit(test)%>%dplyr::select(c("sexo", "cocaina","crack", "favela","testemunha_acus","denuncia", "muita_quantidade","confissao")), type = "response")
a=ifelse(na.omit(test)%>%dplyr::select(condenado)=="Sim",1,0)
b=ifelse(predRL>0.05,1,0)
confusionMatrix(a,b)
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/Fellipe/Dropbox/RPubs/Projeto Estagio")
library(readr)
#Pacotes utilizados:
library(dplyr)
library(ggplot2)
library(GGally)
library(gridExtra)
library(ROCR)
library(tabplot)
library(knitr)
library(kableExtra)
library(caret)
# library(devtools)
# library(scales)
# library(reshape)
# library(rattle)
dados <- read_csv("C:/Users/Fellipe/Dropbox/RPubs/Projeto Estagio/classificado_classe_unica_prioridade.csv")
trainControl = trainControl(method="cv", number=10, classProbs = T)
tree = train(classes ~. , data = dados, method="rpart", trControl=trainControl)
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/Fellipe/Dropbox/RPubs/Projeto Estagio")
library(readr)
#Pacotes utilizados:
library(dplyr)
library(ggplot2)
library(GGally)
library(gridExtra)
library(ROCR)
library(tabplot)
library(knitr)
library(kableExtra)
library(caret)
# library(devtools)
# library(scales)
# library(reshape)
# library(rattle)
dados <- read_csv("C:/Users/Fellipe/Dropbox/RPubs/Projeto Estagio/classificado_classe_unica_prioridade.csv")
dados=dados[,-1]
glimpse(dados)
dados$classes=as.factor(dados$classes)
dados$key=as.factor(dados$key)
dados$sentence=as.factor(dados$sentence)
dados=as.data.frame(dados)
kable(dados, "html")%>%
kable_styling()%>%
scroll_box(width = "1000px", height = "500px")
tableplot(dados, sortCol = classes)
ggplot(data=dados,aes( x=key, fill=classes))+geom_bar()
ggplot(data=dados,aes( x=sentences, fill=classes))+geom_bar()
ggplot(data=dados,aes( x=sentence, fill=classes))+geom_bar()
na.omit(dados)%>%
summary()%>%
t()%>%
kable( "html")%>%
kable_styling()
my_fn <- function(data, mapping, method="loess", ...){
p <- ggplot(data = data, mapping = mapping) +
geom_point() +
geom_smooth(method=method, ...)
p
}
ggpairs(dados, lower = list(continuous = my_fn))
g1=ggcorr(dados,method = c("pairwise", "spearman"), nbreaks = 9)
trainControl = trainControl(method="cv", number=10, classProbs = T)
tree = train(classes ~. , data = dados, method="rpart", trControl=trainControl)
glimpse(dados)
tree = train(classes ~. , data = data.frame(dados), method="rpart", trControl=trainControl)
glimpse(dados)
tree = train(classes ~. , data = data.frame(dados), method="rpart", trControl=trainControl)
glimpse(dados)
tree = train(classes ~ key + sentence , data = data.frame(dados), method="rpart", trControl=trainControl)
glimpse(dados)
dados=as.data.frame(dados)
glimpse(dados)
dados
table(dados)
base=as.matrix(dados)
X= base[,-1]
Y=decodeClassLabels(base[,1])
X= dados[,-1]
Y=decodeClassLabels(dados[,1])
dados[,1]
Y=decodeClassLabels(dados[,1])
library(RSNNS)
library(nnet)
base=as.matrix(dados)
base=as.matrix(dados)
base=as.matrix(dados)
X= dados[,-1]
Y=decodeClassLabels(dados[,1])
d_separado=splitForTrainingAndTest(X,Y,ratio=0.1)
d_normalizado=normTrainingAndTestSet(d_separado, dontNormTargets = TRUE, type="0_1")
modelo_mlp= mlp(d_separado$inputsTrain,
d_separado$targetsTrain,
size=c(3),
maxit=1000,
initFunc = "Randomize_Weights",
#learnFunc = "Std_Backpropagation",
learnFuncParams = c(0.2),
hiddenActFunc = "Act_Logistic",
shufflePatterns = T,
linOut = T,
inputsTest = d_separado$inputsTest,
targetsTest = d_separado$targetsTest);modelo_mlp
X
base=as.matrix(dados)
fpr(i in 1:3){
for(i in 1:3){
base[,i]=as.numeric(dados[,i])
}
base
X= dados[,-1]
Y=decodeClassLabels(dados[,1])
d_normalizado=normTrainingAndTestSet(d_separado, dontNormTargets = TRUE, type="0_1")
d_separado=splitForTrainingAndTest(X,Y,ratio=0.1)
modelo_mlp= mlp(d_separado$inputsTrain,
d_separado$targetsTrain,
size=c(3),
maxit=1000,
initFunc = "Randomize_Weights",
#learnFunc = "Std_Backpropagation",
learnFuncParams = c(0.2),
hiddenActFunc = "Act_Logistic",
shufflePatterns = T,
linOut = T,
inputsTest = d_separado$inputsTest,
targetsTest = d_separado$targetsTest);modelo_mlp
base=as.matrix(dados)
for(i in 1:3){
base[,i]=as.numeric(dados[,i])
}
glimpse(base)
head(base)
for(i in 1:3){
base[,i]=as.factor(dados[,i])
}
for(i in 1:3){
base[,i]=as.numeric(dados[,i])
}
X= dados[,-1]
Y=decodeClassLabels(dados[,1])
modelo_mlp= mlp(d_separado$inputsTrain,
d_separado$targetsTrain,
size=c(3),
maxit=1000,
initFunc = "Randomize_Weights",
#learnFunc = "Std_Backpropagation",
learnFuncParams = c(0.2),
hiddenActFunc = "Act_Logistic",
shufflePatterns = T,
linOut = T,
inputsTest = d_separado$inputsTest,
targetsTest = d_separado$targetsTest);modelo_mlp
X= base[,-1]
d_separado=splitForTrainingAndTest(X,Y,ratio=0.1)
modelo_mlp= mlp(d_separado$inputsTrain,
d_separado$targetsTrain,
size=c(3),
maxit=1000,
initFunc = "Randomize_Weights",
#learnFunc = "Std_Backpropagation",
learnFuncParams = c(0.2),
hiddenActFunc = "Act_Logistic",
shufflePatterns = T,
linOut = T,
inputsTest = d_separado$inputsTest,
targetsTest = d_separado$targetsTest);modelo_mlp
X
base=as.matrix(base)
head(base)
base=as.data.frame(base)
for(i in 1:3){
base[,i]=as.numeric(dados[,i])
}
head(base)
X= base[,-1]
d_separado=splitForTrainingAndTest(X,Y,ratio=0.1)
modelo_mlp= mlp(d_separado$inputsTrain,
d_separado$targetsTrain,
size=c(3),
maxit=1000,
initFunc = "Randomize_Weights",
#learnFunc = "Std_Backpropagation",
learnFuncParams = c(0.2),
hiddenActFunc = "Act_Logistic",
shufflePatterns = T,
linOut = T,
inputsTest = d_separado$inputsTest,
targetsTest = d_separado$targetsTest);modelo_mlp
plot(modelo_mlp$IterativeFitError, type="n", main="Curva de Aprendizagem", xlab="Iteração", ylab="Erro médio quadrado", cex.lab=1.5)
#Plotagem para curva de aprendizado:
plot(modelo_mlp$IterativeFitError, type="n", main="Curva de Aprendizagem", xlab="Iteração", ylab="Erro médio quadrado", cex.lab=1.5)
lines(modelo_mlp$IterativeFitError,col="1", lwd=3, cex=2) #Erro quadrado medio a cada iteração para o conjunto de treinamento
lines(modelo_mlp$IterativeTestError, col="2", lwd=3, cex=2) ##Erro quadrado medio a cada iteração para o conjunto de teste
legend("top", c("Treinamento", "Teste"), lty=c(1,1), col=c(1,2)) #Clicar para legenda aparecer
library(devtools)
plot.nnet(modelo_mlp)
predictions = predict(modelo_mlp,d_separado$inputsTest)[,1]
a=d_separado$targetsTest[,1]
b=ifelse(predictions>0.5,1,0);length(b)
confusionMatrix(a,b)
confusionMatrix(a,b)
caret::confusionMatrix(a,b)
predictions = predict(modelo_mlp,d_separado$inputsTest)[,1]
predictions
predictions = predict(modelo_mlp,d_separado$inputsTest)
caret::confusionMatrix(predictions,d_separado$targetsTest)
confusionMatrix(predictions,d_separado$targetsTest)
predictions
d_separado$targetsTest
b=ifelse(predictions>0.5,1,0);length(b)
confusionMatrix(b,d_separado$targetsTest)
caret::confusionMatrix(b,d_separado$targetsTest)
#Funcao de correlacoes
my_fn <- function(data, mapping, method="loess", ...){
p <- ggplot(data = data, mapping = mapping) +
geom_point() +
geom_smooth(method=method, ...)
p
}
ggpairs(dados, lower = list(continuous = my_fn))
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/Fellipe/Dropbox/RPubs/Projeto Estagio")
library(readr)
#Pacotes utilizados:
library(dplyr)
library(ggplot2)
library(GGally)
library(gridExtra)
library(ROCR)
library(tabplot)
library(knitr)
library(kableExtra)
library(caret)
# library(devtools)
# library(scales)
# library(reshape)
# library(rattle)
dados <- read_csv("C:/Users/Fellipe/Dropbox/RPubs/Projeto Estagio/classificado_classe_unica_prioridade.csv")
dados=dados[,-1]
glimpse(dados)
dados$classes=as.factor(dados$classes)
dados$key=as.factor(dados$key)
dados$sentence=as.factor(dados$sentence)
dados=as.data.frame(dados)
base=as.matrix(dados)
for(i in 1:3){
base[,i]=as.numeric(dados[,i])
}
for(i in 1:3){
base[,i]=as.factor(dados[,i])
}
base=as.data.frame(base)
for(i in 1:3){
base[,i]=as.numeric(dados[,i])
}
head(base)
kable(dados, "html")%>%
kable_styling()%>%
scroll_box(width = "1000px", height = "500px")
tableplot(dados, sortCol = classes)
ggplot(data=dados,aes( x=key, fill=classes))+geom_bar()
ggplot(data=dados,aes( x=sentence, fill=classes))+geom_bar()
na.omit(dados)%>%
summary()%>%
t()%>%
kable( "html")%>%
kable_styling()
#Funcao de correlacoes
my_fn <- function(data, mapping, method="loess", ...){
p <- ggplot(data = data, mapping = mapping) +
geom_point() +
geom_smooth(method=method, ...)
p
}
ggpairs(dados, lower = list(continuous = my_fn))
ggpairs(base, lower = list(continuous = my_fn))
ggpairs(base, lower = list(continuous = my_fn))
g1=ggcorr(base,method = c("pairwise", "spearman"), nbreaks = 9)
g2=ggcorr(base,method = c("pairwise", "spearman"), nbreaks = 12)
gridExtra::grid.arrange(g1,g2,ncol=2)
# Treino
set.seed(22-10-2017)
amostra=sample(1:2, length(dados$classes), replace=T, prob=c(0.7,1-0.7))
train=dados[amostra==1,]
test=dados[amostra==2,]
#PAcotes utilizados:
install.packages("e1071")
library("e1071")
#Criando o modelo:
modelo=naiveBayes(train[,-1],train[,1])
#Fazendo uma predicao:
previsao=predict(modelo, test[,-1], type="class");previsao
resposta=test[,1]
confusionMatrix(previsao,resposta)
install.packages("e1071")
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/Fellipe/Dropbox/RPubs/Projeto Estagio")
library(readr)
#Pacotes utilizados:
library(dplyr)
library(ggplot2)
library(GGally)
library(gridExtra)
library(ROCR)
library(tabplot)
library(knitr)
library(kableExtra)
library(caret)
# library(devtools)
# library(scales)
# library(reshape)
# library(rattle)
dados <- read_csv("C:/Users/Fellipe/Dropbox/RPubs/Projeto Estagio/classificado_classe_unica_prioridade.csv")
# Treino
set.seed(22-10-2017)
amostra=sample(1:2, length(dados$classes), replace=T, prob=c(0.7,1-0.7))
train=dados[amostra==1,]
test=dados[amostra==2,]
#PAcotes utilizados:
install.packages("e1071")
library("e1071")
library("e1071")
modelo=naiveBayes(train[,-1],train[,1])
install.packages("e1071")
library("e1071")
modelo=naiveBayes(train[,-1],train[,1])
modelo=naiveBayes(train[,-1],train[,1])
