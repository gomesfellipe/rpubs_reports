---
title: "Classificação com Naive Bayes"
author: "Fellipe Gomes"
date: "31 de outubro de 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/Fellipe/Dropbox/RPubs/Projeto Estagio")

#Pacotes utilizados:
library(readr)
library(dplyr)
library(ggplot2)
library(GGally)
library(gridExtra)
library(ROCR)
library(tabplot)
library(knitr)
library(kableExtra)
library(caret)
library("e1071")

# library(devtools)
# library(scales)
# library(reshape)
# library(rattle)
dados <- read_csv("C:/Users/Fellipe/Dropbox/RPubs/Projeto Estagio/classificado_classe_unica_prioridade.csv")
```

```{r}
dados=dados[,-1]
glimpse(dados)
dados$classes=as.factor(dados$classes)
dados$key=as.factor(dados$key)
dados$sentence=as.factor(dados$sentence)
dados=as.data.frame(dados)


base=as.matrix(dados)
for(i in 1:3){
  base[,i]=as.numeric(dados[,i])
}

for(i in 1:3){
  base[,i]=as.factor(dados[,i])
}

base=as.data.frame(base)

for(i in 1:3){
  base[,i]=as.numeric(dados[,i])
}
head(base)

```

## Banco de dados:

```{r,echo=F}
kable(dados, "html")%>%
  kable_styling()%>%
  scroll_box(width = "1000px", height = "500px")
```



### Distribuição do bando de dados:
A seguir confere-se a distribuição do bando de dados sendo a condenação pelo artigo 33:

```{r, echo=F}
tableplot(dados, sortCol = classes)
```


```{r}
ggplot(data=dados,aes( x=key, fill=classes))+geom_bar()

ggplot(data=dados,aes( x=sentence, fill=classes))+geom_bar()
```

## Estatística descritiva

A seguir o resumo dos dados da tabela:

```{r,echo=F}
na.omit(dados)%>%
summary()%>%
  t()%>%
  kable( "html")%>%
  kable_styling()

```

# Gráfico de Dispersão e modelo loess

Além disso, podemos visualizar os gráficos de dispersão com ajustes de regressões logísticas de cada variável para explicar a probabilidade de ser condenado, veja:

```{r, echo=F}
g1=ggcorr(base,method = c("pairwise", "spearman"), nbreaks = 9)
g2=ggcorr(base,method = c("pairwise", "spearman"), nbreaks = 12)
gridExtra::grid.arrange(g1,g2,ncol=2)

```


## Naive Bayes:

```{r}


# Treino
set.seed(22-10-2017)
amostra=sample(1:2, length(dados$classes), replace=T, prob=c(0.7,1-0.7))
train=dados[amostra==1,]
test=dados[amostra==2,]


#Criando o modelo:
modelo=naiveBayes(train[,-1],train[,1])

#Fazendo uma predicao:
previsao=predict(modelo, test[,-1], type="class");previsao
resposta=test[,1]

confusionMatrix(previsao,resposta)
```

```{python}
#Import Library of Gaussian Naive Bayes model
from sklearn.naive_bayes import GaussianNB
import numpy as np

#assigning predictor and target variables
x= np.array([[-3,7],[1,5], [1,2], [-2,0], [2,3], [-4,0], [-1,1], [1,1], [-2,2], [2,7], [-4,1], [-2,7]])
Y = np.array([3, 3, 3, 3, 4, 3, 3, 4, 3, 4, 4, 4])

#Create a Gaussian Classifier
model = GaussianNB()

# Train the model using the training sets 
model.fit(x, y)

#Predict Output 
predicted= model.predict([[1,2],[3,4]])
print(predicted)

```


